2023-04-26 05:25:35.254677: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2023-04-26 05:25:37.766210: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-04-26 05:25:37.767302: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2023-04-26 05:25:37.804081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3d:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-26 05:25:37.804121: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2023-04-26 05:25:37.806911: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2023-04-26 05:25:37.806969: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2023-04-26 05:25:37.809055: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-04-26 05:25:37.809712: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-04-26 05:25:37.812069: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-04-26 05:25:37.813499: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2023-04-26 05:25:37.818182: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2023-04-26 05:25:37.819390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2023-04-26 05:25:38.560540: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-04-26 05:25:38.561832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3d:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-26 05:25:38.561873: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2023-04-26 05:25:38.561897: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2023-04-26 05:25:38.561905: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2023-04-26 05:25:38.561914: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-04-26 05:25:38.561922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-04-26 05:25:38.561930: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-04-26 05:25:38.561938: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2023-04-26 05:25:38.561947: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2023-04-26 05:25:38.563354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2023-04-26 05:25:38.563386: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2023-04-26 05:25:39.218459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-04-26 05:25:39.218512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2023-04-26 05:25:39.218519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2023-04-26 05:25:39.220571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10076 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:3d:00.0, compute capability: 7.5)
2023-04-26 05:25:39.220851: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-04-26 05:25:39.397878: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2023-04-26 05:25:39.398561: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
WARNING:tensorflow:AutoGraph could not transform <function train_step_topdown_gru at 0x15548d6034c0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Index'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Num GPUs Available:  1
Load tokenizer...
Prepare training data...
Load model...
Start epochs...
WARNING:tensorflow:AutoGraph could not transform <bound method TopDownCoreAlter.call of <models.TopDown_GRU.TopDownCoreAlter object at 0x15548dd72a00>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Index'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
2023-04-26 05:25:52.625970: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
Epoch 1 Batch 0 Loss 2.7042
Epoch 1 Batch 100 Loss 1.7055
Epoch 1 Batch 200 Loss 1.6659
Epoch 1 Batch 300 Loss 1.4848
Epoch 1 Batch 400 Loss 1.5156
Epoch 1 Loss 1.576590
Time taken for 1 epoch 77.95 sec

Epoch 2 Batch 0 Loss 1.2714
Epoch 2 Batch 100 Loss 1.4255
Epoch 2 Batch 200 Loss 1.2384
Epoch 2 Batch 300 Loss 1.1881
Epoch 2 Batch 400 Loss 1.2295
Epoch 2 Loss 1.238258
Time taken for 1 epoch 65.06 sec

Epoch 3 Batch 0 Loss 1.1702
Epoch 3 Batch 100 Loss 1.0217
Epoch 3 Batch 200 Loss 1.1192
Epoch 3 Batch 300 Loss 0.9637
Epoch 3 Batch 400 Loss 1.0091
Epoch 3 Loss 1.067143
Time taken for 1 epoch 65.19 sec

Epoch 4 Batch 0 Loss 0.8854
Epoch 4 Batch 100 Loss 0.8941
Epoch 4 Batch 200 Loss 1.0892
Epoch 4 Batch 300 Loss 0.8171
Epoch 4 Batch 400 Loss 0.8825
Epoch 4 Loss 0.966637
Time taken for 1 epoch 65.28 sec

Epoch 5 Batch 0 Loss 0.9193
Epoch 5 Batch 100 Loss 0.9211
Epoch 5 Batch 200 Loss 0.8444
Epoch 5 Batch 300 Loss 0.8367
Epoch 5 Batch 400 Loss 0.7858
Epoch 5 Loss 0.889582
Time taken for 1 epoch 65.21 sec

Epoch 6 Batch 0 Loss 0.7743
Epoch 6 Batch 100 Loss 0.8661
Epoch 6 Batch 200 Loss 0.9517
Epoch 6 Batch 300 Loss 0.8264
Epoch 6 Batch 400 Loss 0.7851
Epoch 6 Loss 0.824488
Time taken for 1 epoch 65.28 sec

Epoch 7 Batch 0 Loss 0.7753
Epoch 7 Batch 100 Loss 0.7619
Epoch 7 Batch 200 Loss 0.7987
Epoch 7 Batch 300 Loss 0.6930
Epoch 7 Batch 400 Loss 0.8056
Epoch 7 Loss 0.767654
Time taken for 1 epoch 65.28 sec

Epoch 8 Batch 0 Loss 0.7308
Epoch 8 Batch 100 Loss 0.7454
Epoch 8 Batch 200 Loss 0.5885
Epoch 8 Batch 300 Loss 0.7477
Epoch 8 Batch 400 Loss 0.6192
Epoch 8 Loss 0.716472
Time taken for 1 epoch 65.26 sec

Epoch 9 Batch 0 Loss 0.7493
Epoch 9 Batch 100 Loss 0.5828
Epoch 9 Batch 200 Loss 0.6551
Epoch 9 Batch 300 Loss 0.6050
Epoch 9 Batch 400 Loss 0.6427
Epoch 9 Loss 0.670282
Time taken for 1 epoch 65.22 sec

Epoch 10 Batch 0 Loss 0.7691
Epoch 10 Batch 100 Loss 0.6235
Epoch 10 Batch 200 Loss 0.6600
Epoch 10 Batch 300 Loss 0.5800
Epoch 10 Batch 400 Loss 0.6466
Epoch 10 Loss 0.628510
Time taken for 1 epoch 65.36 sec

Epoch 11 Batch 0 Loss 0.6142
Epoch 11 Batch 100 Loss 0.6454
Epoch 11 Batch 200 Loss 0.5796
Epoch 11 Batch 300 Loss 0.5635
Epoch 11 Batch 400 Loss 0.5625
Epoch 11 Loss 0.589154
Time taken for 1 epoch 65.39 sec

Epoch 12 Batch 0 Loss 0.5456
Epoch 12 Batch 100 Loss 0.6251
Epoch 12 Batch 200 Loss 0.5359
Epoch 12 Batch 300 Loss 0.5086
Epoch 12 Batch 400 Loss 0.5101
Epoch 12 Loss 0.553656
Time taken for 1 epoch 65.31 sec

Epoch 13 Batch 0 Loss 0.5346
Epoch 13 Batch 100 Loss 0.4926
Epoch 13 Batch 200 Loss 0.6082
Epoch 13 Batch 300 Loss 0.5084
Epoch 13 Batch 400 Loss 0.4242
Epoch 13 Loss 0.519364
Time taken for 1 epoch 65.39 sec

Epoch 14 Batch 0 Loss 0.5229
Epoch 14 Batch 100 Loss 0.5481
Epoch 14 Batch 200 Loss 0.4335
Epoch 14 Batch 300 Loss 0.4395
Epoch 14 Batch 400 Loss 0.4555
Epoch 14 Loss 0.489180
Time taken for 1 epoch 65.18 sec

Epoch 15 Batch 0 Loss 0.5361
Epoch 15 Batch 100 Loss 0.4592
Epoch 15 Batch 200 Loss 0.4737
Epoch 15 Batch 300 Loss 0.4792
Epoch 15 Batch 400 Loss 0.4689
Epoch 15 Loss 0.460553
Time taken for 1 epoch 65.37 sec

Epoch 16 Batch 0 Loss 0.5082
Epoch 16 Batch 100 Loss 0.4204
Epoch 16 Batch 200 Loss 0.4676
Epoch 16 Batch 300 Loss 0.4388
Epoch 16 Batch 400 Loss 0.3870
Epoch 16 Loss 0.433063
Time taken for 1 epoch 65.33 sec

Epoch 17 Batch 0 Loss 0.4330
Epoch 17 Batch 100 Loss 0.4150
Epoch 17 Batch 200 Loss 0.3934
Epoch 17 Batch 300 Loss 0.3604
Epoch 17 Batch 400 Loss 0.3362
Epoch 17 Loss 0.408190
Time taken for 1 epoch 65.19 sec

Epoch 18 Batch 0 Loss 0.3840
Epoch 18 Batch 100 Loss 0.3671
Epoch 18 Batch 200 Loss 0.3812
Epoch 18 Batch 300 Loss 0.3790
Epoch 18 Batch 400 Loss 0.3886
Epoch 18 Loss 0.384388
Time taken for 1 epoch 65.26 sec

Epoch 19 Batch 0 Loss 0.3994
Epoch 19 Batch 100 Loss 0.4043
Epoch 19 Batch 200 Loss 0.3670
Epoch 19 Batch 300 Loss 0.3537
Epoch 19 Batch 400 Loss 0.3644
Epoch 19 Loss 0.361047
Time taken for 1 epoch 65.17 sec

Epoch 20 Batch 0 Loss 0.3084
Epoch 20 Batch 100 Loss 0.3465
Epoch 20 Batch 200 Loss 0.3205
Epoch 20 Batch 300 Loss 0.3174
Epoch 20 Batch 400 Loss 0.3209
Epoch 20 Loss 0.340872
Time taken for 1 epoch 65.08 sec

Epoch 21 Batch 0 Loss 0.3711
Epoch 21 Batch 100 Loss 0.3199
Epoch 21 Batch 200 Loss 0.3190
Epoch 21 Batch 300 Loss 0.3303
Epoch 21 Batch 400 Loss 0.3048
Epoch 21 Loss 0.321916
Time taken for 1 epoch 65.27 sec

Epoch 22 Batch 0 Loss 0.3054
Epoch 22 Batch 100 Loss 0.3205
Epoch 22 Batch 200 Loss 0.3087
Epoch 22 Batch 300 Loss 0.3049
Epoch 22 Batch 400 Loss 0.2565
Epoch 22 Loss 0.305232
Time taken for 1 epoch 65.18 sec

Epoch 23 Batch 0 Loss 0.3202
Epoch 23 Batch 100 Loss 0.2830
Epoch 23 Batch 200 Loss 0.2621
Epoch 23 Batch 300 Loss 0.2936
Epoch 23 Batch 400 Loss 0.2639
Epoch 23 Loss 0.287461
Time taken for 1 epoch 65.14 sec

Epoch 24 Batch 0 Loss 0.2899
Epoch 24 Batch 100 Loss 0.2665
Epoch 24 Batch 200 Loss 0.2583
Epoch 24 Batch 300 Loss 0.2581
Epoch 24 Batch 400 Loss 0.2789
Epoch 24 Loss 0.273235
Time taken for 1 epoch 65.34 sec

Epoch 25 Batch 0 Loss 0.3043
Epoch 25 Batch 100 Loss 0.2568
Epoch 25 Batch 200 Loss 0.2618
Epoch 25 Batch 300 Loss 0.2518
Epoch 25 Batch 400 Loss 0.2419
Epoch 25 Loss 0.260699
Time taken for 1 epoch 65.16 sec

Epoch 26 Batch 0 Loss 0.2690
Epoch 26 Batch 100 Loss 0.2282
Epoch 26 Batch 200 Loss 0.2309
Epoch 26 Batch 300 Loss 0.2320
Epoch 26 Batch 400 Loss 0.2439
Epoch 26 Loss 0.247341
Time taken for 1 epoch 65.27 sec

Epoch 27 Batch 0 Loss 0.2543
Epoch 27 Batch 100 Loss 0.2589
Epoch 27 Batch 200 Loss 0.2650
Epoch 27 Batch 300 Loss 0.2494
Epoch 27 Batch 400 Loss 0.2396
Epoch 27 Loss 0.235027
Time taken for 1 epoch 65.18 sec

Epoch 28 Batch 0 Loss 0.2591
Epoch 28 Batch 100 Loss 0.2376
Epoch 28 Batch 200 Loss 0.2221
Epoch 28 Batch 300 Loss 0.1998
Epoch 28 Batch 400 Loss 0.2485
Epoch 28 Loss 0.224850
Time taken for 1 epoch 65.15 sec

Epoch 29 Batch 0 Loss 0.2418
Epoch 29 Batch 100 Loss 0.2205
Epoch 29 Batch 200 Loss 0.2242
Epoch 29 Batch 300 Loss 0.2049
Epoch 29 Batch 400 Loss 0.1992
Epoch 29 Loss 0.216826
Time taken for 1 epoch 65.28 sec

Epoch 30 Batch 0 Loss 0.2267
Epoch 30 Batch 100 Loss 0.2029
Epoch 30 Batch 200 Loss 0.2097
Epoch 30 Batch 300 Loss 0.1719
Epoch 30 Batch 400 Loss 0.1994
Epoch 30 Loss 0.209116
Time taken for 1 epoch 65.35 sec

Epoch 31 Batch 0 Loss 0.2148
Epoch 31 Batch 100 Loss 0.1967
Epoch 31 Batch 200 Loss 0.2006
Epoch 31 Batch 300 Loss 0.1767
Epoch 31 Batch 400 Loss 0.2072
Epoch 31 Loss 0.202299
Time taken for 1 epoch 65.26 sec

Epoch 32 Batch 0 Loss 0.2173
Epoch 32 Batch 100 Loss 0.2043
Epoch 32 Batch 200 Loss 0.1949
Epoch 32 Batch 300 Loss 0.1867
Epoch 32 Batch 400 Loss 0.1953
Epoch 32 Loss 0.194671
Time taken for 1 epoch 67.65 sec

Epoch 33 Batch 0 Loss 0.2057
Epoch 33 Batch 100 Loss 0.1727
Epoch 33 Batch 200 Loss 0.1913
Epoch 33 Batch 300 Loss 0.1989
Epoch 33 Batch 400 Loss 0.1636
Epoch 33 Loss 0.188571
Time taken for 1 epoch 65.37 sec

Epoch 34 Batch 0 Loss 0.1825
Epoch 34 Batch 100 Loss 0.1814
Epoch 34 Batch 200 Loss 0.1852
Epoch 34 Batch 300 Loss 0.1623
Epoch 34 Batch 400 Loss 0.1764
Epoch 34 Loss 0.183003
Time taken for 1 epoch 65.25 sec

Epoch 35 Batch 0 Loss 0.1987
Epoch 35 Batch 100 Loss 0.1671
Epoch 35 Batch 200 Loss 0.1758
Epoch 35 Batch 300 Loss 0.1643
Epoch 35 Batch 400 Loss 0.1815
Epoch 35 Loss 0.176083
Time taken for 1 epoch 65.37 sec

Epoch 36 Batch 0 Loss 0.2050
Epoch 36 Batch 100 Loss 0.1730
Epoch 36 Batch 200 Loss 0.1546
Epoch 36 Batch 300 Loss 0.1622
Epoch 36 Batch 400 Loss 0.1739
Epoch 36 Loss 0.171292
Time taken for 1 epoch 65.44 sec

Epoch 37 Batch 0 Loss 0.1793
Epoch 37 Batch 100 Loss 0.1766
Epoch 37 Batch 200 Loss 0.1625
Epoch 37 Batch 300 Loss 0.1561
Epoch 37 Batch 400 Loss 0.1521
Epoch 37 Loss 0.169075
Time taken for 1 epoch 66.70 sec

Epoch 38 Batch 0 Loss 0.1837
Epoch 38 Batch 100 Loss 0.1728
Epoch 38 Batch 200 Loss 0.1466
Epoch 38 Batch 300 Loss 0.1703
Epoch 38 Batch 400 Loss 0.1529
Epoch 38 Loss 0.165486
Time taken for 1 epoch 65.23 sec

Epoch 39 Batch 0 Loss 0.1952
Epoch 39 Batch 100 Loss 0.1461
Epoch 39 Batch 200 Loss 0.1575
Epoch 39 Batch 300 Loss 0.1539
Epoch 39 Batch 400 Loss 0.1664
Epoch 39 Loss 0.162598
Time taken for 1 epoch 65.21 sec

Epoch 40 Batch 0 Loss 0.1749
Epoch 40 Batch 100 Loss 0.1618
Epoch 40 Batch 200 Loss 0.1634
Epoch 40 Batch 300 Loss 0.1561
Epoch 40 Batch 400 Loss 0.1542
Epoch 40 Loss 0.159088
Time taken for 1 epoch 65.35 sec

Saving models...
Finished
2023-04-26 06:09:28.291008: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2023-04-26 06:09:31.473515: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-04-26 06:09:31.474621: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2023-04-26 06:09:31.509274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3d:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-26 06:09:31.509325: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2023-04-26 06:09:31.512162: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2023-04-26 06:09:31.512240: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2023-04-26 06:09:31.514350: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-04-26 06:09:31.515076: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-04-26 06:09:31.517392: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-04-26 06:09:31.518841: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2023-04-26 06:09:31.523455: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2023-04-26 06:09:31.524674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2023-04-26 06:09:31.669306: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-04-26 06:09:31.670310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3d:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-26 06:09:31.670355: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2023-04-26 06:09:31.670391: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2023-04-26 06:09:31.670401: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2023-04-26 06:09:31.670411: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-04-26 06:09:31.670421: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-04-26 06:09:31.670431: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-04-26 06:09:31.670441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2023-04-26 06:09:31.670451: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2023-04-26 06:09:31.671487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2023-04-26 06:09:31.671518: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2023-04-26 06:09:32.298182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-04-26 06:09:32.298441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2023-04-26 06:09:32.298451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2023-04-26 06:09:32.300214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10076 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:3d:00.0, compute capability: 7.5)
2023-04-26 06:09:32.300480: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-04-26 06:09:32.489426: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2023-04-26 06:09:32.489815: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
2023-04-26 06:09:32.669927: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
Num GPUs Available:  1
Load tokenizer...
Prepare test data...
Load model...
Start evaluating...
Finished
2023-04-26 06:09:55.581885: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2023-04-26 06:09:57.479475: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-04-26 06:09:57.480516: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2023-04-26 06:09:57.520532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3d:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-26 06:09:57.520587: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2023-04-26 06:09:57.522594: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2023-04-26 06:09:57.522653: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2023-04-26 06:09:57.524346: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-04-26 06:09:57.524645: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-04-26 06:09:57.526574: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-04-26 06:09:57.527861: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2023-04-26 06:09:57.532057: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2023-04-26 06:09:57.533238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2023-04-26 06:10:01.332147: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-04-26 06:10:01.333588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3d:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-26 06:10:01.333644: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2023-04-26 06:10:01.333681: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2023-04-26 06:10:01.333694: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2023-04-26 06:10:01.333707: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-04-26 06:10:01.333718: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-04-26 06:10:01.333730: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-04-26 06:10:01.333742: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2023-04-26 06:10:01.333754: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2023-04-26 06:10:01.334774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2023-04-26 06:10:01.334803: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2023-04-26 06:10:01.965247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-04-26 06:10:01.965291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2023-04-26 06:10:01.965298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2023-04-26 06:10:01.967143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10076 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:3d:00.0, compute capability: 7.5)
2023-04-26 06:10:01.967831: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-04-26 06:10:02.290104: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2023-04-26 06:10:02.290543: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
WARNING:tensorflow:AutoGraph could not transform <function train_step_topdown_gru at 0x15548c6043a0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Index'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Num GPUs Available:  1
Load tokenizer...
Prepare training data...
Load model...
Start epochs...
WARNING:tensorflow:AutoGraph could not transform <bound method TopDownCoreAlter.call of <models.TopDown_GRU.TopDownCoreAlter object at 0x1554e96afc40>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Index'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
2023-04-26 06:10:30.594671: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
