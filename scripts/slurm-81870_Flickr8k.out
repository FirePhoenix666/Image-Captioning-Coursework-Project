2023-04-19 08:13:43.922400: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2023-04-19 08:13:46.371573: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-04-19 08:13:46.372582: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2023-04-19 08:13:46.479438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3d:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 08:13:46.480009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:3e:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 08:13:46.480534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: 
pciBusID: 0000:41:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 08:13:46.481058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: 
pciBusID: 0000:42:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 08:13:46.481078: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2023-04-19 08:13:46.483705: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2023-04-19 08:13:46.483763: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2023-04-19 08:13:46.485758: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-04-19 08:13:46.486410: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-04-19 08:13:46.488564: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-04-19 08:13:46.489960: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2023-04-19 08:13:46.494278: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2023-04-19 08:13:46.498398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3
2023-04-19 08:13:47.231227: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-04-19 08:13:47.738772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3d:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 08:13:47.739323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:3e:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 08:13:47.739831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: 
pciBusID: 0000:41:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 08:13:47.740346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: 
pciBusID: 0000:42:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 08:13:47.740374: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2023-04-19 08:13:47.740395: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2023-04-19 08:13:47.740405: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2023-04-19 08:13:47.740415: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-04-19 08:13:47.740424: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-04-19 08:13:47.740433: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-04-19 08:13:47.740442: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2023-04-19 08:13:47.740451: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2023-04-19 08:13:47.744297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3
2023-04-19 08:13:47.744335: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2023-04-19 08:13:49.312807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-04-19 08:13:49.313046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 2 3 
2023-04-19 08:13:49.313055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N N N N 
2023-04-19 08:13:49.313060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   N N N N 
2023-04-19 08:13:49.313064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 2:   N N N N 
2023-04-19 08:13:49.313068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 3:   N N N N 
2023-04-19 08:13:49.316489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10076 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:3d:00.0, compute capability: 7.5)
2023-04-19 08:13:49.317794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10076 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:3e:00.0, compute capability: 7.5)
2023-04-19 08:13:49.319371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10076 MB memory) -> physical GPU (device: 2, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:41:00.0, compute capability: 7.5)
2023-04-19 08:13:49.320513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10076 MB memory) -> physical GPU (device: 3, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:42:00.0, compute capability: 7.5)
2023-04-19 08:13:49.320657: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-04-19 08:13:49.484087: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2023-04-19 08:13:49.484545: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
WARNING:tensorflow:AutoGraph could not transform <function train_step_showtell at 0x1554ac037670> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Index'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Num GPUs Available:  4
Load tokenizer...
Prepare training data using a Tensorflow dataset...
Training...
Start epochs...
WARNING:tensorflow:Gradients do not exist for variables ['cnn__encoder/dense/kernel:0', 'cnn__encoder/dense/bias:0'] when minimizing the loss.
WARNING:tensorflow:Gradients do not exist for variables ['cnn__encoder/dense/kernel:0', 'cnn__encoder/dense/bias:0'] when minimizing the loss.
2023-04-19 08:13:54.141309: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
Epoch 1 Batch 0 Loss 2.7480
Epoch 1 Batch 100 Loss 1.6468
Epoch 1 Batch 200 Loss 1.4150
Epoch 1 Batch 300 Loss 1.5135
Epoch 1 Batch 400 Loss 1.3400
Epoch 1 Loss 1.582725
Time taken for 1 epoch 23.20 sec

Epoch 2 Batch 0 Loss 1.1937
Epoch 2 Batch 100 Loss 1.2810
Epoch 2 Batch 200 Loss 1.2077
Epoch 2 Batch 300 Loss 1.2020
Epoch 2 Batch 400 Loss 1.2029
Epoch 2 Loss 1.259925
Time taken for 1 epoch 18.55 sec

Epoch 3 Batch 0 Loss 1.2114
Epoch 3 Batch 100 Loss 1.1276
Epoch 3 Batch 200 Loss 1.2167
Epoch 3 Batch 300 Loss 1.1270
Epoch 3 Batch 400 Loss 1.0804
Epoch 3 Loss 1.163745
Time taken for 1 epoch 18.49 sec

Epoch 4 Batch 0 Loss 1.0838
Epoch 4 Batch 100 Loss 1.1143
Epoch 4 Batch 200 Loss 1.0888
Epoch 4 Batch 300 Loss 1.1638
Epoch 4 Batch 400 Loss 1.0246
Epoch 4 Loss 1.101404
Time taken for 1 epoch 18.46 sec

Epoch 5 Batch 0 Loss 1.0948
Epoch 5 Batch 100 Loss 1.0983
Epoch 5 Batch 200 Loss 1.1243
Epoch 5 Batch 300 Loss 0.9927
Epoch 5 Batch 400 Loss 1.0239
Epoch 5 Loss 1.056613
Time taken for 1 epoch 18.51 sec

Epoch 6 Batch 0 Loss 1.0666
Epoch 6 Batch 100 Loss 0.9934
Epoch 6 Batch 200 Loss 1.0545
Epoch 6 Batch 300 Loss 0.9869
Epoch 6 Batch 400 Loss 0.9627
Epoch 6 Loss 1.019158
Time taken for 1 epoch 18.42 sec

Epoch 7 Batch 0 Loss 0.9901
Epoch 7 Batch 100 Loss 1.0353
Epoch 7 Batch 200 Loss 0.9906
Epoch 7 Batch 300 Loss 0.9554
Epoch 7 Batch 400 Loss 1.0074
Epoch 7 Loss 0.986745
Time taken for 1 epoch 18.49 sec

Epoch 8 Batch 0 Loss 0.8351
Epoch 8 Batch 100 Loss 0.9752
Epoch 8 Batch 200 Loss 0.9795
Epoch 8 Batch 300 Loss 0.9469
Epoch 8 Batch 400 Loss 0.9196
Epoch 8 Loss 0.957957
Time taken for 1 epoch 18.43 sec

Epoch 9 Batch 0 Loss 0.9408
Epoch 9 Batch 100 Loss 0.9737
Epoch 9 Batch 200 Loss 1.0177
Epoch 9 Batch 300 Loss 0.9326
Epoch 9 Batch 400 Loss 0.9679
Epoch 9 Loss 0.932106
Time taken for 1 epoch 18.47 sec

Epoch 10 Batch 0 Loss 0.9398
Epoch 10 Batch 100 Loss 0.9218
Epoch 10 Batch 200 Loss 0.9122
Epoch 10 Batch 300 Loss 0.9547
Epoch 10 Batch 400 Loss 0.9030
Epoch 10 Loss 0.907366
Time taken for 1 epoch 18.48 sec

Epoch 11 Batch 0 Loss 0.8867
Epoch 11 Batch 100 Loss 0.9443
Epoch 11 Batch 200 Loss 0.8677
Epoch 11 Batch 300 Loss 0.8121
Epoch 11 Batch 400 Loss 0.9072
Epoch 11 Loss 0.884374
Time taken for 1 epoch 18.48 sec

Epoch 12 Batch 0 Loss 0.8324
Epoch 12 Batch 100 Loss 0.8848
Epoch 12 Batch 200 Loss 0.9454
Epoch 12 Batch 300 Loss 0.7276
Epoch 12 Batch 400 Loss 0.8145
Epoch 12 Loss 0.863046
Time taken for 1 epoch 18.41 sec

Epoch 13 Batch 0 Loss 0.9780
Epoch 13 Batch 100 Loss 0.8740
Epoch 13 Batch 200 Loss 0.8541
Epoch 13 Batch 300 Loss 0.8640
Epoch 13 Batch 400 Loss 0.8243
Epoch 13 Loss 0.842532
Time taken for 1 epoch 18.47 sec

Epoch 14 Batch 0 Loss 0.8243
Epoch 14 Batch 100 Loss 0.8717
Epoch 14 Batch 200 Loss 0.7696
Epoch 14 Batch 300 Loss 0.8467
Epoch 14 Batch 400 Loss 0.8150
Epoch 14 Loss 0.823551
Time taken for 1 epoch 18.41 sec

Epoch 15 Batch 0 Loss 0.8067
Epoch 15 Batch 100 Loss 0.8342
Epoch 15 Batch 200 Loss 0.7875
Epoch 15 Batch 300 Loss 0.8020
Epoch 15 Batch 400 Loss 0.7876
Epoch 15 Loss 0.805524
Time taken for 1 epoch 18.34 sec

Epoch 16 Batch 0 Loss 0.7999
Epoch 16 Batch 100 Loss 0.8454
Epoch 16 Batch 200 Loss 0.7298
Epoch 16 Batch 300 Loss 0.7574
Epoch 16 Batch 400 Loss 0.8348
Epoch 16 Loss 0.788293
Time taken for 1 epoch 18.44 sec

Epoch 17 Batch 0 Loss 0.8078
Epoch 17 Batch 100 Loss 0.7116
Epoch 17 Batch 200 Loss 0.8302
Epoch 17 Batch 300 Loss 0.6978
Epoch 17 Batch 400 Loss 0.7415
Epoch 17 Loss 0.771951
Time taken for 1 epoch 18.45 sec

Epoch 18 Batch 0 Loss 0.8377
Epoch 18 Batch 100 Loss 0.7424
Epoch 18 Batch 200 Loss 0.7400
Epoch 18 Batch 300 Loss 0.7504
Epoch 18 Batch 400 Loss 0.7282
Epoch 18 Loss 0.756377
Time taken for 1 epoch 18.41 sec

Epoch 19 Batch 0 Loss 0.7988
Epoch 19 Batch 100 Loss 0.7906
Epoch 19 Batch 200 Loss 0.7507
Epoch 19 Batch 300 Loss 0.7198
Epoch 19 Batch 400 Loss 0.7533
Epoch 19 Loss 0.741292
Time taken for 1 epoch 18.57 sec

Epoch 20 Batch 0 Loss 0.7801
Epoch 20 Batch 100 Loss 0.6673
Epoch 20 Batch 200 Loss 0.7188
Epoch 20 Batch 300 Loss 0.6720
Epoch 20 Batch 400 Loss 0.7745
Epoch 20 Loss 0.726502
Time taken for 1 epoch 18.36 sec

Epoch 21 Batch 0 Loss 0.7521
Epoch 21 Batch 100 Loss 0.6526
Epoch 21 Batch 200 Loss 0.6853
Epoch 21 Batch 300 Loss 0.7124
Epoch 21 Batch 400 Loss 0.6997
Epoch 21 Loss 0.712718
Time taken for 1 epoch 18.37 sec

Epoch 22 Batch 0 Loss 0.7181
Epoch 22 Batch 100 Loss 0.6993
Epoch 22 Batch 200 Loss 0.7101
Epoch 22 Batch 300 Loss 0.6792
Epoch 22 Batch 400 Loss 0.6587
Epoch 22 Loss 0.699309
Time taken for 1 epoch 18.43 sec

Epoch 23 Batch 0 Loss 0.6983
Epoch 23 Batch 100 Loss 0.6976
Epoch 23 Batch 200 Loss 0.7030
Epoch 23 Batch 300 Loss 0.6909
Epoch 23 Batch 400 Loss 0.6727
Epoch 23 Loss 0.686185
Time taken for 1 epoch 18.56 sec

Epoch 24 Batch 0 Loss 0.7000
Epoch 24 Batch 100 Loss 0.6566
Epoch 24 Batch 200 Loss 0.6961
Epoch 24 Batch 300 Loss 0.6279
Epoch 24 Batch 400 Loss 0.6798
Epoch 24 Loss 0.673534
Time taken for 1 epoch 18.45 sec

Epoch 25 Batch 0 Loss 0.7165
Epoch 25 Batch 100 Loss 0.6668
Epoch 25 Batch 200 Loss 0.6518
Epoch 25 Batch 300 Loss 0.6452
Epoch 25 Batch 400 Loss 0.6762
Epoch 25 Loss 0.661023
Time taken for 1 epoch 18.45 sec

Epoch 26 Batch 0 Loss 0.6838
Epoch 26 Batch 100 Loss 0.7048
Epoch 26 Batch 200 Loss 0.6419
Epoch 26 Batch 300 Loss 0.6323
Epoch 26 Batch 400 Loss 0.6531
Epoch 26 Loss 0.648923
Time taken for 1 epoch 18.44 sec

Epoch 27 Batch 0 Loss 0.6613
Epoch 27 Batch 100 Loss 0.6627
Epoch 27 Batch 200 Loss 0.6111
Epoch 27 Batch 300 Loss 0.6472
Epoch 27 Batch 400 Loss 0.6044
Epoch 27 Loss 0.636940
Time taken for 1 epoch 18.48 sec

Epoch 28 Batch 0 Loss 0.6842
Epoch 28 Batch 100 Loss 0.6135
Epoch 28 Batch 200 Loss 0.6074
Epoch 28 Batch 300 Loss 0.6047
Epoch 28 Batch 400 Loss 0.6207
Epoch 28 Loss 0.625372
Time taken for 1 epoch 18.39 sec

Epoch 29 Batch 0 Loss 0.6249
Epoch 29 Batch 100 Loss 0.6258
Epoch 29 Batch 200 Loss 0.6300
Epoch 29 Batch 300 Loss 0.6142
Epoch 29 Batch 400 Loss 0.5660
Epoch 29 Loss 0.613951
Time taken for 1 epoch 18.54 sec

Epoch 30 Batch 0 Loss 0.6513
Epoch 30 Batch 100 Loss 0.6149
Epoch 30 Batch 200 Loss 0.5929
Epoch 30 Batch 300 Loss 0.5870
Epoch 30 Batch 400 Loss 0.6015
Epoch 30 Loss 0.602796
Time taken for 1 epoch 18.37 sec

Epoch 31 Batch 0 Loss 0.6274
Epoch 31 Batch 100 Loss 0.5859
Epoch 31 Batch 200 Loss 0.5684
Epoch 31 Batch 300 Loss 0.5622
Epoch 31 Batch 400 Loss 0.5431
Epoch 31 Loss 0.592317
Time taken for 1 epoch 18.57 sec

Epoch 32 Batch 0 Loss 0.6262
Epoch 32 Batch 100 Loss 0.6163
Epoch 32 Batch 200 Loss 0.5657
Epoch 32 Batch 300 Loss 0.5304
Epoch 32 Batch 400 Loss 0.5486
Epoch 32 Loss 0.581364
Time taken for 1 epoch 18.39 sec

Epoch 33 Batch 0 Loss 0.6385
Epoch 33 Batch 100 Loss 0.5544
Epoch 33 Batch 200 Loss 0.5836
Epoch 33 Batch 300 Loss 0.5816
Epoch 33 Batch 400 Loss 0.5555
Epoch 33 Loss 0.571490
Time taken for 1 epoch 18.42 sec

Epoch 34 Batch 0 Loss 0.6135
Epoch 34 Batch 100 Loss 0.5555
Epoch 34 Batch 200 Loss 0.5337
Epoch 34 Batch 300 Loss 0.5441
Epoch 34 Batch 400 Loss 0.5591
Epoch 34 Loss 0.561076
Time taken for 1 epoch 18.40 sec

Epoch 35 Batch 0 Loss 0.5941
Epoch 35 Batch 100 Loss 0.5606
Epoch 35 Batch 200 Loss 0.5206
Epoch 35 Batch 300 Loss 0.5300
Epoch 35 Batch 400 Loss 0.5554
Epoch 35 Loss 0.551512
Time taken for 1 epoch 18.48 sec

Epoch 36 Batch 0 Loss 0.6112
Epoch 36 Batch 100 Loss 0.5427
Epoch 36 Batch 200 Loss 0.5519
Epoch 36 Batch 300 Loss 0.5311
Epoch 36 Batch 400 Loss 0.5256
Epoch 36 Loss 0.542116
Time taken for 1 epoch 18.44 sec

Epoch 37 Batch 0 Loss 0.5268
Epoch 37 Batch 100 Loss 0.5419
Epoch 37 Batch 200 Loss 0.5355
Epoch 37 Batch 300 Loss 0.5546
Epoch 37 Batch 400 Loss 0.5277
Epoch 37 Loss 0.533009
Time taken for 1 epoch 18.42 sec

Epoch 38 Batch 0 Loss 0.6131
Epoch 38 Batch 100 Loss 0.4980
Epoch 38 Batch 200 Loss 0.5308
Epoch 38 Batch 300 Loss 0.5194
Epoch 38 Batch 400 Loss 0.5473
Epoch 38 Loss 0.524061
Time taken for 1 epoch 18.52 sec

Epoch 39 Batch 0 Loss 0.5644
Epoch 39 Batch 100 Loss 0.5207
Epoch 39 Batch 200 Loss 0.5040
Epoch 39 Batch 300 Loss 0.4768
Epoch 39 Batch 400 Loss 0.4899
Epoch 39 Loss 0.514934
Time taken for 1 epoch 18.37 sec

Epoch 40 Batch 0 Loss 0.5522
Epoch 40 Batch 100 Loss 0.5287
Epoch 40 Batch 200 Loss 0.5174
Epoch 40 Batch 300 Loss 0.5170
Epoch 40 Batch 400 Loss 0.5323
Epoch 40 Loss 0.506615
Time taken for 1 epoch 18.38 sec

2023-04-19 08:26:14.013795: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2023-04-19 08:26:16.419801: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-04-19 08:26:16.420820: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2023-04-19 08:26:16.522873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3d:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 08:26:16.523445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:3e:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 08:26:16.523969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: 
pciBusID: 0000:41:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 08:26:16.524490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: 
pciBusID: 0000:42:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 08:26:16.524510: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2023-04-19 08:26:16.527154: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2023-04-19 08:26:16.527212: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2023-04-19 08:26:16.529205: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-04-19 08:26:16.529870: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-04-19 08:26:16.532072: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-04-19 08:26:16.533463: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2023-04-19 08:26:16.537838: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2023-04-19 08:26:16.541974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3
2023-04-19 08:26:17.280255: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-04-19 08:26:17.773698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3d:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 08:26:17.774269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:3e:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 08:26:17.774787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: 
pciBusID: 0000:41:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 08:26:17.775296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: 
pciBusID: 0000:42:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 08:26:17.775328: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2023-04-19 08:26:17.775350: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2023-04-19 08:26:17.775359: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2023-04-19 08:26:17.775368: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-04-19 08:26:17.775376: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-04-19 08:26:17.775385: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-04-19 08:26:17.775393: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2023-04-19 08:26:17.775402: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2023-04-19 08:26:17.779330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3
2023-04-19 08:26:17.779369: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2023-04-19 08:26:19.380124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-04-19 08:26:19.380394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 2 3 
2023-04-19 08:26:19.380404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N N N N 
2023-04-19 08:26:19.380409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   N N N N 
2023-04-19 08:26:19.380413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 2:   N N N N 
2023-04-19 08:26:19.380417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 3:   N N N N 
2023-04-19 08:26:19.383937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10076 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:3d:00.0, compute capability: 7.5)
2023-04-19 08:26:19.385286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10076 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:3e:00.0, compute capability: 7.5)
2023-04-19 08:26:19.386908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10076 MB memory) -> physical GPU (device: 2, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:41:00.0, compute capability: 7.5)
2023-04-19 08:26:19.388091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10076 MB memory) -> physical GPU (device: 3, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:42:00.0, compute capability: 7.5)
2023-04-19 08:26:19.388244: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-04-19 08:26:19.558972: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2023-04-19 08:26:19.559401: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
WARNING:tensorflow:AutoGraph could not transform <function train_step_bahdanau at 0x1554ac0398b0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Index'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Num GPUs Available:  4
Load tokenizer...
Prepare training data using a Tensorflow dataset...
Training...
Start epochs...
WARNING:tensorflow:AutoGraph could not transform <bound method RNN_Decoder.call of <models.BahdanauAttend.RNN_Decoder object at 0x1554ac07cc40>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Index'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
2023-04-19 08:26:43.001641: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
Epoch 1 Batch 0 Loss 2.5243
Epoch 1 Batch 100 Loss 1.6179
Epoch 1 Batch 200 Loss 1.5387
Epoch 1 Batch 300 Loss 1.3799
Epoch 1 Batch 400 Loss 1.2582
Epoch 1 Loss 1.496319
Time taken for 1 epoch 55.95 sec

Epoch 2 Batch 0 Loss 1.1802
Epoch 2 Batch 100 Loss 1.1765
Epoch 2 Batch 200 Loss 1.1178
Epoch 2 Batch 300 Loss 1.1081
Epoch 2 Batch 400 Loss 1.0935
Epoch 2 Loss 1.138636
Time taken for 1 epoch 32.63 sec

Epoch 3 Batch 0 Loss 1.1171
Epoch 3 Batch 100 Loss 1.0440
Epoch 3 Batch 200 Loss 1.0466
Epoch 3 Batch 300 Loss 0.9966
Epoch 3 Batch 400 Loss 0.9759
Epoch 3 Loss 1.016279
Time taken for 1 epoch 32.62 sec

Epoch 4 Batch 0 Loss 0.8343
Epoch 4 Batch 100 Loss 0.8973
Epoch 4 Batch 200 Loss 0.9301
Epoch 4 Batch 300 Loss 0.9154
Epoch 4 Batch 400 Loss 0.9895
Epoch 4 Loss 0.936505
Time taken for 1 epoch 32.63 sec

Epoch 5 Batch 0 Loss 0.8458
Epoch 5 Batch 100 Loss 0.8720
Epoch 5 Batch 200 Loss 0.8835
Epoch 5 Batch 300 Loss 0.8969
Epoch 5 Batch 400 Loss 0.8578
Epoch 5 Loss 0.873315
Time taken for 1 epoch 32.58 sec

Epoch 6 Batch 0 Loss 0.8177
Epoch 6 Batch 100 Loss 0.7514
Epoch 6 Batch 200 Loss 0.8061
Epoch 6 Batch 300 Loss 0.8149
Epoch 6 Batch 400 Loss 0.7707
Epoch 6 Loss 0.819473
Time taken for 1 epoch 32.59 sec

Epoch 7 Batch 0 Loss 0.7916
Epoch 7 Batch 100 Loss 0.7556
Epoch 7 Batch 200 Loss 0.7955
Epoch 7 Batch 300 Loss 0.7797
Epoch 7 Batch 400 Loss 0.8664
Epoch 7 Loss 0.770611
Time taken for 1 epoch 32.65 sec

Epoch 8 Batch 0 Loss 0.6974
Epoch 8 Batch 100 Loss 0.7154
Epoch 8 Batch 200 Loss 0.7711
Epoch 8 Batch 300 Loss 0.6786
Epoch 8 Batch 400 Loss 0.6682
Epoch 8 Loss 0.727197
Time taken for 1 epoch 32.69 sec

Epoch 9 Batch 0 Loss 0.6781
Epoch 9 Batch 100 Loss 0.6953
Epoch 9 Batch 200 Loss 0.7156
Epoch 9 Batch 300 Loss 0.7251
Epoch 9 Batch 400 Loss 0.6570
Epoch 9 Loss 0.687473
Time taken for 1 epoch 32.61 sec

Epoch 10 Batch 0 Loss 0.5402
Epoch 10 Batch 100 Loss 0.7086
Epoch 10 Batch 200 Loss 0.6647
Epoch 10 Batch 300 Loss 0.6231
Epoch 10 Batch 400 Loss 0.5967
Epoch 10 Loss 0.651424
Time taken for 1 epoch 32.57 sec

Epoch 11 Batch 0 Loss 0.6965
Epoch 11 Batch 100 Loss 0.6574
Epoch 11 Batch 200 Loss 0.6298
Epoch 11 Batch 300 Loss 0.5723
Epoch 11 Batch 400 Loss 0.6092
Epoch 11 Loss 0.617355
Time taken for 1 epoch 32.61 sec

Epoch 12 Batch 0 Loss 0.6288
Epoch 12 Batch 100 Loss 0.6118
Epoch 12 Batch 200 Loss 0.6134
Epoch 12 Batch 300 Loss 0.6192
Epoch 12 Batch 400 Loss 0.5928
Epoch 12 Loss 0.587663
Time taken for 1 epoch 32.85 sec

Epoch 13 Batch 0 Loss 0.5763
Epoch 13 Batch 100 Loss 0.5438
Epoch 13 Batch 200 Loss 0.5731
Epoch 13 Batch 300 Loss 0.5728
Epoch 13 Batch 400 Loss 0.5188
Epoch 13 Loss 0.558166
Time taken for 1 epoch 32.68 sec

Epoch 14 Batch 0 Loss 0.5523
Epoch 14 Batch 100 Loss 0.5319
Epoch 14 Batch 200 Loss 0.5439
Epoch 14 Batch 300 Loss 0.5238
Epoch 14 Batch 400 Loss 0.5125
Epoch 14 Loss 0.529875
Time taken for 1 epoch 32.61 sec

Epoch 15 Batch 0 Loss 0.5680
Epoch 15 Batch 100 Loss 0.5146
Epoch 15 Batch 200 Loss 0.5830
Epoch 15 Batch 300 Loss 0.5791
Epoch 15 Batch 400 Loss 0.4848
Epoch 15 Loss 0.504301
Time taken for 1 epoch 32.64 sec

Epoch 16 Batch 0 Loss 0.5165
Epoch 16 Batch 100 Loss 0.5091
Epoch 16 Batch 200 Loss 0.4745
Epoch 16 Batch 300 Loss 0.4718
Epoch 16 Batch 400 Loss 0.4422
Epoch 16 Loss 0.481470
Time taken for 1 epoch 32.64 sec

Epoch 17 Batch 0 Loss 0.4646
Epoch 17 Batch 100 Loss 0.4477
Epoch 17 Batch 200 Loss 0.4760
Epoch 17 Batch 300 Loss 0.4491
Epoch 17 Batch 400 Loss 0.3960
Epoch 17 Loss 0.460274
Time taken for 1 epoch 32.66 sec

Epoch 18 Batch 0 Loss 0.4650
Epoch 18 Batch 100 Loss 0.4296
Epoch 18 Batch 200 Loss 0.4405
Epoch 18 Batch 300 Loss 0.4653
Epoch 18 Batch 400 Loss 0.4804
Epoch 18 Loss 0.439750
Time taken for 1 epoch 32.66 sec

Epoch 19 Batch 0 Loss 0.4179
Epoch 19 Batch 100 Loss 0.4545
Epoch 19 Batch 200 Loss 0.4367
Epoch 19 Batch 300 Loss 0.4264
Epoch 19 Batch 400 Loss 0.4671
Epoch 19 Loss 0.419887
Time taken for 1 epoch 32.58 sec

Epoch 20 Batch 0 Loss 0.3865
Epoch 20 Batch 100 Loss 0.3768
Epoch 20 Batch 200 Loss 0.3933
Epoch 20 Batch 300 Loss 0.3728
Epoch 20 Batch 400 Loss 0.3951
Epoch 20 Loss 0.403542
Time taken for 1 epoch 32.57 sec

Epoch 21 Batch 0 Loss 0.4306
Epoch 21 Batch 100 Loss 0.3988
Epoch 21 Batch 200 Loss 0.3571
Epoch 21 Batch 300 Loss 0.3811
Epoch 21 Batch 400 Loss 0.3510
Epoch 21 Loss 0.386171
Time taken for 1 epoch 32.61 sec

Epoch 22 Batch 0 Loss 0.3782
Epoch 22 Batch 100 Loss 0.4385
Epoch 22 Batch 200 Loss 0.4194
Epoch 22 Batch 300 Loss 0.3495
Epoch 22 Batch 400 Loss 0.3780
Epoch 22 Loss 0.375847
Time taken for 1 epoch 32.59 sec

Epoch 23 Batch 0 Loss 0.4122
Epoch 23 Batch 100 Loss 0.3883
Epoch 23 Batch 200 Loss 0.3970
Epoch 23 Batch 300 Loss 0.3602
Epoch 23 Batch 400 Loss 0.3545
Epoch 23 Loss 0.357842
Time taken for 1 epoch 32.67 sec

Epoch 24 Batch 0 Loss 0.3476
Epoch 24 Batch 100 Loss 0.3695
Epoch 24 Batch 200 Loss 0.3233
Epoch 24 Batch 300 Loss 0.3204
Epoch 24 Batch 400 Loss 0.3758
Epoch 24 Loss 0.343914
Time taken for 1 epoch 32.55 sec

Epoch 25 Batch 0 Loss 0.3551
Epoch 25 Batch 100 Loss 0.3630
Epoch 25 Batch 200 Loss 0.3442
Epoch 25 Batch 300 Loss 0.3412
Epoch 25 Batch 400 Loss 0.3634
Epoch 25 Loss 0.332165
Time taken for 1 epoch 32.66 sec

Epoch 26 Batch 0 Loss 0.3567
Epoch 26 Batch 100 Loss 0.3378
Epoch 26 Batch 200 Loss 0.3228
Epoch 26 Batch 300 Loss 0.3466
Epoch 26 Batch 400 Loss 0.2937
Epoch 26 Loss 0.321508
Time taken for 1 epoch 32.59 sec

Epoch 27 Batch 0 Loss 0.3310
Epoch 27 Batch 100 Loss 0.3041
Epoch 27 Batch 200 Loss 0.3200
Epoch 27 Batch 300 Loss 0.3107
Epoch 27 Batch 400 Loss 0.2795
Epoch 27 Loss 0.320447
Time taken for 1 epoch 32.64 sec

Epoch 28 Batch 0 Loss 0.3215
Epoch 28 Batch 100 Loss 0.3303
Epoch 28 Batch 200 Loss 0.2853
Epoch 28 Batch 300 Loss 0.2683
Epoch 28 Batch 400 Loss 0.3188
Epoch 28 Loss 0.302991
Time taken for 1 epoch 32.57 sec

Epoch 29 Batch 0 Loss 0.3293
Epoch 29 Batch 100 Loss 0.2861
Epoch 29 Batch 200 Loss 0.2736
Epoch 29 Batch 300 Loss 0.2560
Epoch 29 Batch 400 Loss 0.2999
Epoch 29 Loss 0.290791
Time taken for 1 epoch 32.69 sec

Epoch 30 Batch 0 Loss 0.2646
Epoch 30 Batch 100 Loss 0.2849
Epoch 30 Batch 200 Loss 0.2816
Epoch 30 Batch 300 Loss 0.2722
Epoch 30 Batch 400 Loss 0.2933
Epoch 30 Loss 0.283162
Time taken for 1 epoch 32.59 sec

Epoch 31 Batch 0 Loss 0.2834
Epoch 31 Batch 100 Loss 0.2996
Epoch 31 Batch 200 Loss 0.2756
Epoch 31 Batch 300 Loss 0.2744
Epoch 31 Batch 400 Loss 0.2764
Epoch 31 Loss 0.276493
Time taken for 1 epoch 32.65 sec

Epoch 32 Batch 0 Loss 0.3108
Epoch 32 Batch 100 Loss 0.2614
Epoch 32 Batch 200 Loss 0.2802
Epoch 32 Batch 300 Loss 0.3080
Epoch 32 Batch 400 Loss 0.2551
Epoch 32 Loss 0.271748
Time taken for 1 epoch 32.55 sec

Epoch 33 Batch 0 Loss 0.2990
Epoch 33 Batch 100 Loss 0.2431
Epoch 33 Batch 200 Loss 0.2523
Epoch 33 Batch 300 Loss 0.2313
Epoch 33 Batch 400 Loss 0.2804
Epoch 33 Loss 0.263806
Time taken for 1 epoch 32.56 sec

Epoch 34 Batch 0 Loss 0.2897
Epoch 34 Batch 100 Loss 0.2635
Epoch 34 Batch 200 Loss 0.2450
Epoch 34 Batch 300 Loss 0.2756
Epoch 34 Batch 400 Loss 0.2610
Epoch 34 Loss 0.257955
Time taken for 1 epoch 32.79 sec

Epoch 35 Batch 0 Loss 0.3648
Epoch 35 Batch 100 Loss 0.2452
Epoch 35 Batch 200 Loss 0.2322
Epoch 35 Batch 300 Loss 0.2278
Epoch 35 Batch 400 Loss 0.2846
Epoch 35 Loss 0.253445
Time taken for 1 epoch 32.52 sec

Epoch 36 Batch 0 Loss 0.2771
Epoch 36 Batch 100 Loss 0.2524
Epoch 36 Batch 200 Loss 0.2172
Epoch 36 Batch 300 Loss 0.2280
Epoch 36 Batch 400 Loss 0.2309
Epoch 36 Loss 0.248949
Time taken for 1 epoch 32.56 sec

Epoch 37 Batch 0 Loss 0.3087
Epoch 37 Batch 100 Loss 0.2342
Epoch 37 Batch 200 Loss 0.2481
Epoch 37 Batch 300 Loss 0.2194
Epoch 37 Batch 400 Loss 0.2393
Epoch 37 Loss 0.246011
Time taken for 1 epoch 32.53 sec

Epoch 38 Batch 0 Loss 0.2383
Epoch 38 Batch 100 Loss 0.2614
Epoch 38 Batch 200 Loss 0.2235
Epoch 38 Batch 300 Loss 0.2464
Epoch 38 Batch 400 Loss 0.2619
Epoch 38 Loss 0.238677
Time taken for 1 epoch 32.48 sec

Epoch 39 Batch 0 Loss 0.2791
Epoch 39 Batch 100 Loss 0.2511
Epoch 39 Batch 200 Loss 0.2238
Epoch 39 Batch 300 Loss 0.2054
Epoch 39 Batch 400 Loss 0.2364
Epoch 39 Loss 0.231837
Time taken for 1 epoch 32.54 sec

Epoch 40 Batch 0 Loss 0.2513
Epoch 40 Batch 100 Loss 0.2016
Epoch 40 Batch 200 Loss 0.2414
Epoch 40 Batch 300 Loss 0.2183
Epoch 40 Batch 400 Loss 0.2008
Epoch 40 Loss 0.229216
Time taken for 1 epoch 32.47 sec

2023-04-19 08:48:29.732620: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2023-04-19 08:48:32.132624: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-04-19 08:48:32.133636: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2023-04-19 08:48:32.234157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3d:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 08:48:32.234730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:3e:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 08:48:32.235254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: 
pciBusID: 0000:41:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 08:48:32.235775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: 
pciBusID: 0000:42:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 08:48:32.235797: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2023-04-19 08:48:32.238413: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2023-04-19 08:48:32.238466: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2023-04-19 08:48:32.240478: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-04-19 08:48:32.241142: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-04-19 08:48:32.243334: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-04-19 08:48:32.244814: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2023-04-19 08:48:32.249153: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2023-04-19 08:48:32.253253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3
2023-04-19 08:48:32.995564: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-04-19 08:48:33.491085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3d:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 08:48:33.491648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:3e:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 08:48:33.492159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: 
pciBusID: 0000:41:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 08:48:33.492666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: 
pciBusID: 0000:42:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 08:48:33.492694: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2023-04-19 08:48:33.492716: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2023-04-19 08:48:33.492725: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2023-04-19 08:48:33.492734: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-04-19 08:48:33.492743: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-04-19 08:48:33.492753: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-04-19 08:48:33.492762: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2023-04-19 08:48:33.492771: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2023-04-19 08:48:33.496633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3
2023-04-19 08:48:33.496670: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2023-04-19 08:48:35.079296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-04-19 08:48:35.079578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 2 3 
2023-04-19 08:48:35.079595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N N N N 
2023-04-19 08:48:35.079600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   N N N N 
2023-04-19 08:48:35.079604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 2:   N N N N 
2023-04-19 08:48:35.079609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 3:   N N N N 
2023-04-19 08:48:35.083097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10076 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:3d:00.0, compute capability: 7.5)
2023-04-19 08:48:35.084425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10076 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:3e:00.0, compute capability: 7.5)
2023-04-19 08:48:35.086016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10076 MB memory) -> physical GPU (device: 2, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:41:00.0, compute capability: 7.5)
2023-04-19 08:48:35.087175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10076 MB memory) -> physical GPU (device: 3, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:42:00.0, compute capability: 7.5)
2023-04-19 08:48:35.087335: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-04-19 08:48:35.252390: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2023-04-19 08:48:35.252816: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
WARNING:tensorflow:AutoGraph could not transform <function train_step_topdown at 0x1554ac03a8b0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Index'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Num GPUs Available:  4
Load tokenizer...
Prepare training data using a Tensorflow dataset...
Training...
Start epochs...
WARNING:tensorflow:AutoGraph could not transform <bound method TopDownCore.call of <models.TopDown.TopDownCore object at 0x1554ac07d1c0>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Index'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
2023-04-19 08:48:46.441494: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
Epoch 1 Batch 0 Loss 2.6824
Epoch 1 Batch 100 Loss 1.5581
Epoch 1 Batch 200 Loss 1.6697
Epoch 1 Batch 300 Loss 1.5584
Epoch 1 Batch 400 Loss 1.5194
Epoch 1 Loss 1.579464
Time taken for 1 epoch 74.27 sec

Epoch 2 Batch 0 Loss 1.4267
Epoch 2 Batch 100 Loss 1.2749
Epoch 2 Batch 200 Loss 1.3402
Epoch 2 Batch 300 Loss 1.1209
Epoch 2 Batch 400 Loss 1.1481
Epoch 2 Loss 1.248650
Time taken for 1 epoch 63.44 sec

Epoch 3 Batch 0 Loss 1.2642
Epoch 3 Batch 100 Loss 1.0635
Epoch 3 Batch 200 Loss 1.1141
Epoch 3 Batch 300 Loss 0.9593
Epoch 3 Batch 400 Loss 1.0704
Epoch 3 Loss 1.089332
Time taken for 1 epoch 63.41 sec

Epoch 4 Batch 0 Loss 0.9446
Epoch 4 Batch 100 Loss 0.9341
Epoch 4 Batch 200 Loss 1.0161
Epoch 4 Batch 300 Loss 0.9632
Epoch 4 Batch 400 Loss 0.9364
Epoch 4 Loss 0.993698
Time taken for 1 epoch 63.44 sec

Epoch 5 Batch 0 Loss 0.9123
Epoch 5 Batch 100 Loss 0.9621
Epoch 5 Batch 200 Loss 0.9465
Epoch 5 Batch 300 Loss 0.9054
Epoch 5 Batch 400 Loss 1.0142
Epoch 5 Loss 0.917550
Time taken for 1 epoch 63.50 sec

Epoch 6 Batch 0 Loss 0.9444
Epoch 6 Batch 100 Loss 0.8504
Epoch 6 Batch 200 Loss 0.8790
Epoch 6 Batch 300 Loss 0.9495
Epoch 6 Batch 400 Loss 0.9001
Epoch 6 Loss 0.853120
Time taken for 1 epoch 63.48 sec

Epoch 7 Batch 0 Loss 0.8942
Epoch 7 Batch 100 Loss 0.7944
Epoch 7 Batch 200 Loss 0.7564
Epoch 7 Batch 300 Loss 0.7748
Epoch 7 Batch 400 Loss 0.7495
Epoch 7 Loss 0.795508
Time taken for 1 epoch 63.50 sec

Epoch 8 Batch 0 Loss 0.7139
Epoch 8 Batch 100 Loss 0.7373
Epoch 8 Batch 200 Loss 0.7356
Epoch 8 Batch 300 Loss 0.6218
Epoch 8 Batch 400 Loss 0.7914
Epoch 8 Loss 0.743407
Time taken for 1 epoch 63.53 sec

Epoch 9 Batch 0 Loss 0.6830
Epoch 9 Batch 100 Loss 0.6733
Epoch 9 Batch 200 Loss 0.6665
Epoch 9 Batch 300 Loss 0.7140
Epoch 9 Batch 400 Loss 0.6950
Epoch 9 Loss 0.696810
Time taken for 1 epoch 63.54 sec

Epoch 10 Batch 0 Loss 0.6766
Epoch 10 Batch 100 Loss 0.6673
Epoch 10 Batch 200 Loss 0.6362
Epoch 10 Batch 300 Loss 0.6252
Epoch 10 Batch 400 Loss 0.5556
Epoch 10 Loss 0.654035
Time taken for 1 epoch 63.46 sec

Epoch 11 Batch 0 Loss 0.6290
Epoch 11 Batch 100 Loss 0.5919
Epoch 11 Batch 200 Loss 0.6191
Epoch 11 Batch 300 Loss 0.5898
Epoch 11 Batch 400 Loss 0.6535
Epoch 11 Loss 0.614726
Time taken for 1 epoch 63.46 sec

Epoch 12 Batch 0 Loss 0.6282
Epoch 12 Batch 100 Loss 0.5540
Epoch 12 Batch 200 Loss 0.5374
Epoch 12 Batch 300 Loss 0.5430
Epoch 12 Batch 400 Loss 0.6126
Epoch 12 Loss 0.578979
Time taken for 1 epoch 63.58 sec

Epoch 13 Batch 0 Loss 0.5075
Epoch 13 Batch 100 Loss 0.5454
Epoch 13 Batch 200 Loss 0.5815
Epoch 13 Batch 300 Loss 0.5067
Epoch 13 Batch 400 Loss 0.5166
Epoch 13 Loss 0.546021
Time taken for 1 epoch 63.48 sec

Epoch 14 Batch 0 Loss 0.4940
Epoch 14 Batch 100 Loss 0.5262
Epoch 14 Batch 200 Loss 0.4956
Epoch 14 Batch 300 Loss 0.4831
Epoch 14 Batch 400 Loss 0.5318
Epoch 14 Loss 0.515662
Time taken for 1 epoch 63.53 sec

Epoch 15 Batch 0 Loss 0.5083
Epoch 15 Batch 100 Loss 0.5097
Epoch 15 Batch 200 Loss 0.4936
Epoch 15 Batch 300 Loss 0.4502
Epoch 15 Batch 400 Loss 0.4796
Epoch 15 Loss 0.486669
Time taken for 1 epoch 63.54 sec

Epoch 16 Batch 0 Loss 0.4574
Epoch 16 Batch 100 Loss 0.4768
Epoch 16 Batch 200 Loss 0.4286
Epoch 16 Batch 300 Loss 0.4430
Epoch 16 Batch 400 Loss 0.4582
Epoch 16 Loss 0.459341
Time taken for 1 epoch 63.51 sec

Epoch 17 Batch 0 Loss 0.4816
Epoch 17 Batch 100 Loss 0.3749
Epoch 17 Batch 200 Loss 0.4833
Epoch 17 Batch 300 Loss 0.4940
Epoch 17 Batch 400 Loss 0.4273
Epoch 17 Loss 0.433072
Time taken for 1 epoch 63.50 sec

Epoch 18 Batch 0 Loss 0.4109
Epoch 18 Batch 100 Loss 0.3744
Epoch 18 Batch 200 Loss 0.4317
Epoch 18 Batch 300 Loss 0.4355
Epoch 18 Batch 400 Loss 0.4024
Epoch 18 Loss 0.409128
Time taken for 1 epoch 63.54 sec

Epoch 19 Batch 0 Loss 0.4300
Epoch 19 Batch 100 Loss 0.4164
Epoch 19 Batch 200 Loss 0.3964
Epoch 19 Batch 300 Loss 0.3839
Epoch 19 Batch 400 Loss 0.3389
Epoch 19 Loss 0.386364
Time taken for 1 epoch 63.44 sec

Epoch 20 Batch 0 Loss 0.4242
Epoch 20 Batch 100 Loss 0.3536
Epoch 20 Batch 200 Loss 0.3612
Epoch 20 Batch 300 Loss 0.3366
Epoch 20 Batch 400 Loss 0.3433
Epoch 20 Loss 0.364683
Time taken for 1 epoch 63.53 sec

Epoch 21 Batch 0 Loss 0.3843
Epoch 21 Batch 100 Loss 0.3567
Epoch 21 Batch 200 Loss 0.3437
Epoch 21 Batch 300 Loss 0.3513
Epoch 21 Batch 400 Loss 0.3497
Epoch 21 Loss 0.344946
Time taken for 1 epoch 63.54 sec

Epoch 22 Batch 0 Loss 0.3139
Epoch 22 Batch 100 Loss 0.3636
Epoch 22 Batch 200 Loss 0.3111
Epoch 22 Batch 300 Loss 0.3223
Epoch 22 Batch 400 Loss 0.2704
Epoch 22 Loss 0.324999
Time taken for 1 epoch 63.61 sec

Epoch 23 Batch 0 Loss 0.3136
Epoch 23 Batch 100 Loss 0.3461
Epoch 23 Batch 200 Loss 0.2828
Epoch 23 Batch 300 Loss 0.2780
Epoch 23 Batch 400 Loss 0.3203
Epoch 23 Loss 0.306153
Time taken for 1 epoch 63.49 sec

Epoch 24 Batch 0 Loss 0.3130
Epoch 24 Batch 100 Loss 0.3090
Epoch 24 Batch 200 Loss 0.2983
Epoch 24 Batch 300 Loss 0.2823
Epoch 24 Batch 400 Loss 0.3036
Epoch 24 Loss 0.289738
Time taken for 1 epoch 63.50 sec

Epoch 25 Batch 0 Loss 0.3196
Epoch 25 Batch 100 Loss 0.2847
Epoch 25 Batch 200 Loss 0.2608
Epoch 25 Batch 300 Loss 0.2525
Epoch 25 Batch 400 Loss 0.2621
Epoch 25 Loss 0.273465
Time taken for 1 epoch 63.46 sec

Epoch 26 Batch 0 Loss 0.2870
Epoch 26 Batch 100 Loss 0.2835
Epoch 26 Batch 200 Loss 0.2612
Epoch 26 Batch 300 Loss 0.2468
Epoch 26 Batch 400 Loss 0.2654
Epoch 26 Loss 0.258067
Time taken for 1 epoch 63.47 sec

Epoch 27 Batch 0 Loss 0.2563
Epoch 27 Batch 100 Loss 0.2334
Epoch 27 Batch 200 Loss 0.2605
Epoch 27 Batch 300 Loss 0.2204
Epoch 27 Batch 400 Loss 0.2563
Epoch 27 Loss 0.244221
Time taken for 1 epoch 63.52 sec

Epoch 28 Batch 0 Loss 0.2290
Epoch 28 Batch 100 Loss 0.2272
Epoch 28 Batch 200 Loss 0.2373
Epoch 28 Batch 300 Loss 0.1962
Epoch 28 Batch 400 Loss 0.2128
Epoch 28 Loss 0.231179
Time taken for 1 epoch 63.49 sec

Epoch 29 Batch 0 Loss 0.2368
Epoch 29 Batch 100 Loss 0.2110
Epoch 29 Batch 200 Loss 0.2058
Epoch 29 Batch 300 Loss 0.2174
Epoch 29 Batch 400 Loss 0.1998
Epoch 29 Loss 0.218992
Time taken for 1 epoch 63.45 sec

Epoch 30 Batch 0 Loss 0.2437
Epoch 30 Batch 100 Loss 0.2394
Epoch 30 Batch 200 Loss 0.2164
Epoch 30 Batch 300 Loss 0.1918
Epoch 30 Batch 400 Loss 0.2023
Epoch 30 Loss 0.208599
Time taken for 1 epoch 63.47 sec

Epoch 31 Batch 0 Loss 0.2021
Epoch 31 Batch 100 Loss 0.1898
Epoch 31 Batch 200 Loss 0.1871
Epoch 31 Batch 300 Loss 0.1947
Epoch 31 Batch 400 Loss 0.1951
Epoch 31 Loss 0.198295
Time taken for 1 epoch 63.47 sec

Epoch 32 Batch 0 Loss 0.2011
Epoch 32 Batch 100 Loss 0.1975
Epoch 32 Batch 200 Loss 0.1984
Epoch 32 Batch 300 Loss 0.1864
Epoch 32 Batch 400 Loss 0.1666
Epoch 32 Loss 0.188730
Time taken for 1 epoch 63.40 sec

Epoch 33 Batch 0 Loss 0.1985
Epoch 33 Batch 100 Loss 0.1822
Epoch 33 Batch 200 Loss 0.1737
Epoch 33 Batch 300 Loss 0.1699
Epoch 33 Batch 400 Loss 0.1642
Epoch 33 Loss 0.180298
Time taken for 1 epoch 63.44 sec

Epoch 34 Batch 0 Loss 0.2064
Epoch 34 Batch 100 Loss 0.1695
Epoch 34 Batch 200 Loss 0.1610
Epoch 34 Batch 300 Loss 0.1749
Epoch 34 Batch 400 Loss 0.1651
Epoch 34 Loss 0.172174
Time taken for 1 epoch 63.43 sec

Epoch 35 Batch 0 Loss 0.1735
Epoch 35 Batch 100 Loss 0.1636
Epoch 35 Batch 200 Loss 0.1475
Epoch 35 Batch 300 Loss 0.1675
Epoch 35 Batch 400 Loss 0.1647
Epoch 35 Loss 0.165254
Time taken for 1 epoch 63.44 sec

Epoch 36 Batch 0 Loss 0.1631
Epoch 36 Batch 100 Loss 0.1521
Epoch 36 Batch 200 Loss 0.1622
Epoch 36 Batch 300 Loss 0.1637
Epoch 36 Batch 400 Loss 0.1566
Epoch 36 Loss 0.159004
Time taken for 1 epoch 63.47 sec

Epoch 37 Batch 0 Loss 0.1654
Epoch 37 Batch 100 Loss 0.1557
Epoch 37 Batch 200 Loss 0.1529
Epoch 37 Batch 300 Loss 0.1405
Epoch 37 Batch 400 Loss 0.1573
Epoch 37 Loss 0.153888
Time taken for 1 epoch 63.45 sec

Epoch 38 Batch 0 Loss 0.1460
Epoch 38 Batch 100 Loss 0.1265
Epoch 38 Batch 200 Loss 0.1430
Epoch 38 Batch 300 Loss 0.1415
Epoch 38 Batch 400 Loss 0.1376
Epoch 38 Loss 0.148130
Time taken for 1 epoch 63.48 sec

Epoch 39 Batch 0 Loss 0.1639
Epoch 39 Batch 100 Loss 0.1491
Epoch 39 Batch 200 Loss 0.1401
Epoch 39 Batch 300 Loss 0.1318
Epoch 39 Batch 400 Loss 0.1535
Epoch 39 Loss 0.144321
Time taken for 1 epoch 63.47 sec

Epoch 40 Batch 0 Loss 0.1367
Epoch 40 Batch 100 Loss 0.1445
Epoch 40 Batch 200 Loss 0.1419
Epoch 40 Batch 300 Loss 0.1438
Epoch 40 Batch 400 Loss 0.1286
Epoch 40 Loss 0.140059
Time taken for 1 epoch 63.47 sec

2023-04-19 09:31:07.581305: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2023-04-19 09:31:10.093392: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-04-19 09:31:10.094622: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2023-04-19 09:31:10.200529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3d:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 09:31:10.201096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:3e:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 09:31:10.201633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: 
pciBusID: 0000:41:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 09:31:10.202152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: 
pciBusID: 0000:42:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 09:31:10.202173: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2023-04-19 09:31:10.205036: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2023-04-19 09:31:10.205092: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2023-04-19 09:31:10.207297: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-04-19 09:31:10.208129: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-04-19 09:31:10.210457: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-04-19 09:31:10.212076: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2023-04-19 09:31:10.216649: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2023-04-19 09:31:10.220777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3
2023-04-19 09:31:10.963011: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-04-19 09:31:11.478224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:3d:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 09:31:11.478795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:3e:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 09:31:11.479304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: 
pciBusID: 0000:41:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 09:31:11.479812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: 
pciBusID: 0000:42:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2023-04-19 09:31:11.479841: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2023-04-19 09:31:11.479862: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2023-04-19 09:31:11.479871: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2023-04-19 09:31:11.479887: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2023-04-19 09:31:11.479896: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2023-04-19 09:31:11.479905: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2023-04-19 09:31:11.479913: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2023-04-19 09:31:11.479922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2023-04-19 09:31:11.483787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3
2023-04-19 09:31:11.483823: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2023-04-19 09:31:13.091175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-04-19 09:31:13.091438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 2 3 
2023-04-19 09:31:13.091447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N N N N 
2023-04-19 09:31:13.091452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   N N N N 
2023-04-19 09:31:13.091456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 2:   N N N N 
2023-04-19 09:31:13.091460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 3:   N N N N 
2023-04-19 09:31:13.096241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10076 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:3d:00.0, compute capability: 7.5)
2023-04-19 09:31:13.097604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10076 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:3e:00.0, compute capability: 7.5)
2023-04-19 09:31:13.099219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10076 MB memory) -> physical GPU (device: 2, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:41:00.0, compute capability: 7.5)
2023-04-19 09:31:13.100387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10076 MB memory) -> physical GPU (device: 3, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:42:00.0, compute capability: 7.5)
2023-04-19 09:31:13.100536: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2023-04-19 09:31:13.283248: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2023-04-19 09:31:13.283673: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
WARNING:tensorflow:AutoGraph could not transform <function train_step_attonatt at 0x1554ac03aaf0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Index'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Num GPUs Available:  4
Load tokenizer...
Prepare training data using a Tensorflow dataset...
Training...
Start epochs...
WARNING:tensorflow:AutoGraph could not transform <bound method AoALayer.call of <models.AoANet.AoALayer object at 0x1554ac0779a0>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Index'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:tensorflow:AutoGraph could not transform <bound method MultiHeadAttention.call of <models.AoANet.MultiHeadAttention object at 0x1554ac077610>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Index'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:tensorflow:AutoGraph could not transform <bound method RNN_Decoder.call of <models.AoANet.RNN_Decoder object at 0x1554a2136730>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Index'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
2023-04-19 09:31:26.216424: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2023-04-19 09:31:26.477014: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
Epoch 1 Batch 0 Loss 2.7939
Epoch 1 Batch 100 Loss 1.5678
Epoch 1 Batch 200 Loss 1.5706
Epoch 1 Batch 300 Loss 1.4850
Epoch 1 Batch 400 Loss 1.5173
Epoch 1 Loss 1.570070
Time taken for 1 epoch 123.88 sec

Epoch 2 Batch 0 Loss 1.4507
Epoch 2 Batch 100 Loss 1.3244
Epoch 2 Batch 200 Loss 1.3484
Epoch 2 Batch 300 Loss 1.1788
Epoch 2 Batch 400 Loss 1.2317
Epoch 2 Loss 1.299411
Time taken for 1 epoch 110.02 sec

Epoch 3 Batch 0 Loss 1.2725
Epoch 3 Batch 100 Loss 1.2228
Epoch 3 Batch 200 Loss 1.1157
Epoch 3 Batch 300 Loss 1.0363
Epoch 3 Batch 400 Loss 1.1229
Epoch 3 Loss 1.130885
Time taken for 1 epoch 110.31 sec

Epoch 4 Batch 0 Loss 1.1066
Epoch 4 Batch 100 Loss 1.0224
Epoch 4 Batch 200 Loss 1.0332
Epoch 4 Batch 300 Loss 0.9830
Epoch 4 Batch 400 Loss 0.9110
Epoch 4 Loss 1.033238
Time taken for 1 epoch 110.17 sec

Epoch 5 Batch 0 Loss 0.9454
Epoch 5 Batch 100 Loss 0.9707
Epoch 5 Batch 200 Loss 1.0235
Epoch 5 Batch 300 Loss 0.9278
Epoch 5 Batch 400 Loss 0.8922
Epoch 5 Loss 0.955259
Time taken for 1 epoch 110.08 sec

Epoch 6 Batch 0 Loss 0.9088
Epoch 6 Batch 100 Loss 0.8606
Epoch 6 Batch 200 Loss 0.9115
Epoch 6 Batch 300 Loss 0.9658
Epoch 6 Batch 400 Loss 0.8162
Epoch 6 Loss 0.885062
Time taken for 1 epoch 110.08 sec

Epoch 7 Batch 0 Loss 0.8147
Epoch 7 Batch 100 Loss 0.8719
Epoch 7 Batch 200 Loss 0.7826
Epoch 7 Batch 300 Loss 0.8799
Epoch 7 Batch 400 Loss 0.7575
Epoch 7 Loss 0.820285
Time taken for 1 epoch 110.26 sec

Epoch 8 Batch 0 Loss 0.8164
Epoch 8 Batch 100 Loss 0.8411
Epoch 8 Batch 200 Loss 0.7829
Epoch 8 Batch 300 Loss 0.7212
Epoch 8 Batch 400 Loss 0.7526
Epoch 8 Loss 0.761702
Time taken for 1 epoch 110.37 sec

Epoch 9 Batch 0 Loss 0.7437
Epoch 9 Batch 100 Loss 0.6770
Epoch 9 Batch 200 Loss 0.6966
Epoch 9 Batch 300 Loss 0.6821
Epoch 9 Batch 400 Loss 0.7412
Epoch 9 Loss 0.706922
Time taken for 1 epoch 110.37 sec

Epoch 10 Batch 0 Loss 0.6659
Epoch 10 Batch 100 Loss 0.6519
Epoch 10 Batch 200 Loss 0.6416
Epoch 10 Batch 300 Loss 0.5952
Epoch 10 Batch 400 Loss 0.6209
Epoch 10 Loss 0.655621
Time taken for 1 epoch 110.42 sec

Epoch 11 Batch 0 Loss 0.5690
Epoch 11 Batch 100 Loss 0.6098
Epoch 11 Batch 200 Loss 0.6211
Epoch 11 Batch 300 Loss 0.5844
Epoch 11 Batch 400 Loss 0.5969
Epoch 11 Loss 0.608040
Time taken for 1 epoch 110.36 sec

Epoch 12 Batch 0 Loss 0.5458
Epoch 12 Batch 100 Loss 0.5504
Epoch 12 Batch 200 Loss 0.5521
Epoch 12 Batch 300 Loss 0.6028
Epoch 12 Batch 400 Loss 0.5009
Epoch 12 Loss 0.563721
Time taken for 1 epoch 110.40 sec

Epoch 13 Batch 0 Loss 0.5418
Epoch 13 Batch 100 Loss 0.5267
Epoch 13 Batch 200 Loss 0.5085
Epoch 13 Batch 300 Loss 0.5329
Epoch 13 Batch 400 Loss 0.5107
Epoch 13 Loss 0.522667
Time taken for 1 epoch 110.50 sec

Epoch 14 Batch 0 Loss 0.5560
Epoch 14 Batch 100 Loss 0.4886
Epoch 14 Batch 200 Loss 0.5328
Epoch 14 Batch 300 Loss 0.5048
Epoch 14 Batch 400 Loss 0.4962
Epoch 14 Loss 0.484705
Time taken for 1 epoch 110.47 sec

Epoch 15 Batch 0 Loss 0.5205
Epoch 15 Batch 100 Loss 0.4767
Epoch 15 Batch 200 Loss 0.4584
Epoch 15 Batch 300 Loss 0.5041
Epoch 15 Batch 400 Loss 0.4521
Epoch 15 Loss 0.452410
Time taken for 1 epoch 110.42 sec

Epoch 16 Batch 0 Loss 0.4396
Epoch 16 Batch 100 Loss 0.4139
Epoch 16 Batch 200 Loss 0.3940
Epoch 16 Batch 300 Loss 0.3955
Epoch 16 Batch 400 Loss 0.4228
Epoch 16 Loss 0.421097
Time taken for 1 epoch 110.45 sec

Epoch 17 Batch 0 Loss 0.4098
Epoch 17 Batch 100 Loss 0.4097
Epoch 17 Batch 200 Loss 0.3606
Epoch 17 Batch 300 Loss 0.4067
Epoch 17 Batch 400 Loss 0.3896
Epoch 17 Loss 0.393593
Time taken for 1 epoch 110.45 sec

Epoch 18 Batch 0 Loss 0.3333
Epoch 18 Batch 100 Loss 0.3676
Epoch 18 Batch 200 Loss 0.4068
Epoch 18 Batch 300 Loss 0.4041
Epoch 18 Batch 400 Loss 0.3394
Epoch 18 Loss 0.366591
Time taken for 1 epoch 110.59 sec

Epoch 19 Batch 0 Loss 0.3605
Epoch 19 Batch 100 Loss 0.3482
Epoch 19 Batch 200 Loss 0.3352
Epoch 19 Batch 300 Loss 0.3599
Epoch 19 Batch 400 Loss 0.3243
Epoch 19 Loss 0.344831
Time taken for 1 epoch 110.49 sec

Epoch 20 Batch 0 Loss 0.3360
Epoch 20 Batch 100 Loss 0.2828
Epoch 20 Batch 200 Loss 0.3456
Epoch 20 Batch 300 Loss 0.3144
Epoch 20 Batch 400 Loss 0.3078
Epoch 20 Loss 0.323024
Time taken for 1 epoch 110.54 sec

Epoch 21 Batch 0 Loss 0.3101
Epoch 21 Batch 100 Loss 0.2830
Epoch 21 Batch 200 Loss 0.2997
Epoch 21 Batch 300 Loss 0.3171
Epoch 21 Batch 400 Loss 0.2722
Epoch 21 Loss 0.304428
Time taken for 1 epoch 110.57 sec

Epoch 22 Batch 0 Loss 0.2803
Epoch 22 Batch 100 Loss 0.2877
Epoch 22 Batch 200 Loss 0.2724
Epoch 22 Batch 300 Loss 0.2784
Epoch 22 Batch 400 Loss 0.3031
Epoch 22 Loss 0.286109
Time taken for 1 epoch 110.52 sec

Epoch 23 Batch 0 Loss 0.2733
Epoch 23 Batch 100 Loss 0.2527
Epoch 23 Batch 200 Loss 0.2682
Epoch 23 Batch 300 Loss 0.2652
Epoch 23 Batch 400 Loss 0.2620
Epoch 23 Loss 0.271044
Time taken for 1 epoch 110.49 sec

Epoch 24 Batch 0 Loss 0.2585
Epoch 24 Batch 100 Loss 0.2471
Epoch 24 Batch 200 Loss 0.2719
Epoch 24 Batch 300 Loss 0.2291
Epoch 24 Batch 400 Loss 0.2716
Epoch 24 Loss 0.257598
Time taken for 1 epoch 110.51 sec

Epoch 25 Batch 0 Loss 0.2867
Epoch 25 Batch 100 Loss 0.2429
Epoch 25 Batch 200 Loss 0.2706
Epoch 25 Batch 300 Loss 0.2247
Epoch 25 Batch 400 Loss 0.2551
Epoch 25 Loss 0.243909
Time taken for 1 epoch 110.50 sec

Epoch 26 Batch 0 Loss 0.2504
Epoch 26 Batch 100 Loss 0.2322
Epoch 26 Batch 200 Loss 0.2451
Epoch 26 Batch 300 Loss 0.2371
Epoch 26 Batch 400 Loss 0.2372
Epoch 26 Loss 0.231170
Time taken for 1 epoch 110.50 sec

Epoch 27 Batch 0 Loss 0.2141
Epoch 27 Batch 100 Loss 0.2078
Epoch 27 Batch 200 Loss 0.2095
Epoch 27 Batch 300 Loss 0.2310
Epoch 27 Batch 400 Loss 0.2177
Epoch 27 Loss 0.220323
Time taken for 1 epoch 110.50 sec

Epoch 28 Batch 0 Loss 0.2264
Epoch 28 Batch 100 Loss 0.2367
Epoch 28 Batch 200 Loss 0.2212
Epoch 28 Batch 300 Loss 0.2247
Epoch 28 Batch 400 Loss 0.2106
Epoch 28 Loss 0.212007
Time taken for 1 epoch 110.50 sec

Epoch 29 Batch 0 Loss 0.1851
Epoch 29 Batch 100 Loss 0.2301
Epoch 29 Batch 200 Loss 0.2252
Epoch 29 Batch 300 Loss 0.2011
Epoch 29 Batch 400 Loss 0.1937
Epoch 29 Loss 0.202308
Time taken for 1 epoch 110.49 sec

Epoch 30 Batch 0 Loss 0.1887
Epoch 30 Batch 100 Loss 0.1904
Epoch 30 Batch 200 Loss 0.1945
Epoch 30 Batch 300 Loss 0.1983
Epoch 30 Batch 400 Loss 0.2260
Epoch 30 Loss 0.194015
Time taken for 1 epoch 110.49 sec

Epoch 31 Batch 0 Loss 0.2156
Epoch 31 Batch 100 Loss 0.1989
Epoch 31 Batch 200 Loss 0.1976
Epoch 31 Batch 300 Loss 0.1774
Epoch 31 Batch 400 Loss 0.1800
Epoch 31 Loss 0.188484
Time taken for 1 epoch 110.51 sec

Epoch 32 Batch 0 Loss 0.1691
Epoch 32 Batch 100 Loss 0.1675
Epoch 32 Batch 200 Loss 0.1934
Epoch 32 Batch 300 Loss 0.1728
Epoch 32 Batch 400 Loss 0.1687
Epoch 32 Loss 0.181326
Time taken for 1 epoch 110.48 sec

Epoch 33 Batch 0 Loss 0.1609
Epoch 33 Batch 100 Loss 0.1815
Epoch 33 Batch 200 Loss 0.1895
Epoch 33 Batch 300 Loss 0.1739
Epoch 33 Batch 400 Loss 0.1903
Epoch 33 Loss 0.176064
Time taken for 1 epoch 110.46 sec

Epoch 34 Batch 0 Loss 0.1843
Epoch 34 Batch 100 Loss 0.1651
Epoch 34 Batch 200 Loss 0.1712
Epoch 34 Batch 300 Loss 0.1631
Epoch 34 Batch 400 Loss 0.1810
Epoch 34 Loss 0.170621
Time taken for 1 epoch 110.45 sec

Epoch 35 Batch 0 Loss 0.1633
Epoch 35 Batch 100 Loss 0.1584
Epoch 35 Batch 200 Loss 0.1655
Epoch 35 Batch 300 Loss 0.1534
Epoch 35 Batch 400 Loss 0.1713
Epoch 35 Loss 0.165385
Time taken for 1 epoch 110.44 sec

Epoch 36 Batch 0 Loss 0.1441
Epoch 36 Batch 100 Loss 0.1531
Epoch 36 Batch 200 Loss 0.1538
Epoch 36 Batch 300 Loss 0.1545
Epoch 36 Batch 400 Loss 0.1687
Epoch 36 Loss 0.161135
Time taken for 1 epoch 110.42 sec

Epoch 37 Batch 0 Loss 0.1501
Epoch 37 Batch 100 Loss 0.1574
Epoch 37 Batch 200 Loss 0.1709
Epoch 37 Batch 300 Loss 0.1777
Epoch 37 Batch 400 Loss 0.1482
Epoch 37 Loss 0.156764
Time taken for 1 epoch 110.40 sec

Epoch 38 Batch 0 Loss 0.1462
Epoch 38 Batch 100 Loss 0.1451
Epoch 38 Batch 200 Loss 0.1558
Epoch 38 Batch 300 Loss 0.1473
Epoch 38 Batch 400 Loss 0.1467
Epoch 38 Loss 0.151672
Time taken for 1 epoch 110.54 sec

Epoch 39 Batch 0 Loss 0.1511
Epoch 39 Batch 100 Loss 0.1581
Epoch 39 Batch 200 Loss 0.1413
Epoch 39 Batch 300 Loss 0.1457
Epoch 39 Batch 400 Loss 0.1464
Epoch 39 Loss 0.148947
Time taken for 1 epoch 110.47 sec

Epoch 40 Batch 0 Loss 0.1368
Epoch 40 Batch 100 Loss 0.1370
Epoch 40 Batch 200 Loss 0.1380
Epoch 40 Batch 300 Loss 0.1346
Epoch 40 Batch 400 Loss 0.1450
Epoch 40 Loss 0.145602
Time taken for 1 epoch 110.50 sec

